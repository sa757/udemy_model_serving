# -*- coding: utf-8 -*-

import pandas as pd
import joblib
from sklearn.pipeline import Pipeline

from modeling_pipeline.config import config
from modeling_pipeline import __version__ as _version

import logging
import typing as t

_logger = logging.getLogger(__name__)


def data_loader(*, file_name: str) -> pd.DataFrame:
    """DESC"""
    return pd.read_csv(f'{config.DATASET_DIR}/{file_name}')


def save_pipeline(*, pipeline_to_persist) -> None:
    """DESC"""
    save_file_name = f'{config.PIPELINE_SAVE_FILE}{_version}.pkl'
    save_path = config.TRAINED_MODEL_DIR / save_file_name
    remove_old_pipelines(files_to_keep=[save_file_name])
    joblib.dump(pipeline_to_persist, save_path)
    _logger.info(f'saved pipeline: {save_file_name}')


def load_pipeline(*, file_name: str) -> Pipeline:
    """DESC"""
    file_path = config.TRAINED_MODEL_DIR / file_name
    trained_model = joblib.load(filename=file_path)
    return trained_model


def remove_old_pipelines(*, files_to_keep: t.List[str]) -> None:
    """DESC"""
    do_not_delete = files_to_keep + ['__init__.py']
    for model_file in config.TRAINED_MODEL_DIR.iterdir():
        if model_file.name not in do_not_delete:
            model_file.unlink()